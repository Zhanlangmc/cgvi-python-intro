{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Algebra\r\n",
    "\r\n",
    "This will cover some of the maths described in the course, and show you how you can implement it in python.\r\n",
    "\r\n",
    "First, let's import the libraries we'll be using in this notebook:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we covered briefly in the numpy notebook, vectors and matrices are represented in numpy as arrays of the right dimensions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "vector = np.array([1,2,3])\r\n",
    "matrix = np.array([\r\n",
    "    [1, 0, 0],\r\n",
    "    [0, 1, 0],\r\n",
    "    [0, 0, 1]\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You could implement the dot and cross products yourself in code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def my_dot_product(a, b):\r\n",
    "    return np.sum(a * b)\r\n",
    "\r\n",
    "def my_cross_product(a, b):\r\n",
    "    return np.array([a[1]*b[2] - a[2]*b[1], a[2]*b[0] - a[0]*b[2], a[0]*b[1] - a[1]*b[0]])\r\n",
    "\r\n",
    "# The dot product of a vector with itself is its length squared:\r\n",
    "print(my_dot_product(vector, vector))\r\n",
    "\r\n",
    "# The cross product of any vector with itself is always the zero vector:\r\n",
    "print(my_cross_product(vector, vector))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "But thankfully numpy has functions implementing these already:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(np.dot(vector, vector))\r\n",
    "print(np.cross(vector, vector))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO visualise some cross products here using matplotlib's 3D plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a reminder, all the standard mathematical operators in numpy `+ - * /` work **element-wise**. This means that `+` is vector addition, but `*` is **not** matrix multiplication.\r\n",
    "\r\n",
    "To do matrix multiplication you must use the np.matmul() function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "another_vector = np.array([4, 5, 6])\r\n",
    "vector_sum = vector + another_vector # This works fine, and does vector addition as you would expect\r\n",
    "print(vector_sum)\r\n",
    "\r\n",
    "multiple = matrix * vector # This does not do matrix multiplication\r\n",
    "# This will use numpy's \"broadcasting\" feature, and make copies of the vector to make it a 3x3 matrix.\r\n",
    "# Then it will multiply both together, giving a 3x3 result\r\n",
    "print(multiple)\r\n",
    "\r\n",
    "# To do real matrix multiplication, use np.matmul()\r\n",
    "matrix_multiply = np.matmul(matrix, vector)\r\n",
    "print(matrix_multiply)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5 7 9]\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Numpy can also invert a matrix for you:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "matrix = np.random.rand(3,3)\r\n",
    "\r\n",
    "matrix_inverse = np.linalg.inv(matrix)\r\n",
    "\r\n",
    "# When multiplying the matrix by its inverse, the result should be close to the identity matrix\r\n",
    "# It won't be exactly the same due to floating point errors\r\n",
    "multiple = np.matmul(matrix_inverse, matrix)\r\n",
    "print(multiple)\r\n",
    "\r\n",
    "# Because it's not exactly the identity, this test won't work:\r\n",
    "print(np.all(multiple == np.eye(3)))\r\n",
    "\r\n",
    "# If you want to check if one numpy array is \"close enough\" to another, you can use np.allclose():\r\n",
    "print(np.allclose(np.matmul(matrix, matrix_inverse), np.eye(3)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 1.00000000e+00  0.00000000e+00  1.11022302e-16]\n",
      " [ 2.22044605e-16  1.00000000e+00 -2.22044605e-16]\n",
      " [-1.66533454e-16  0.00000000e+00  1.00000000e+00]]\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can only invert square matrices, so the following won't work:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "matrix = np.random.rand(2,3)\r\n",
    "matrix_inverse = np.linalg.inv(matrix) # This throws LinAlgError as the input isn't square."
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-8c3fac153a39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmatrix_inverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# This throws LinAlgError as the input isn't square.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[0m_assert_stacked_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m     \u001b[0m_assert_stacked_square\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_assert_stacked_square\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Last 2 dimensions of the array must be square'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_assert_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we covered in the course, TODO talk about SVD"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "86014d7f00cdc48111f14ffa351be1944e0fd5daba15176dac9ddff10091d234"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}